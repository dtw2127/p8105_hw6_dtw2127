p8105_hw6_dtw2127
================
Dee Wang
03/12/2021

Load birth weight data and convert variables to factors where
appropriate.

``` r
birthweight = read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(babysex),
    babysex = fct_recode(babysex, "male" = "1", "female" = "2"),
    frace = as.factor(frace),
    frace = fct_recode(frace, "white" = "1", "black" = "2", "asian" = "3", 
                       "puerto rican" = "4", "other" = "8"),
    malform = as.logical(malform),
    mrace = as.factor(mrace),
    mrace = fct_recode(mrace, "white" = "1", "black" = "2", "asian" = "3", 
                       "puerto rican" = "4"))
```

    ## Rows: 4342 Columns: 20

    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...

    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

We’ll use a combination of the knowledge base on factors associated with
birth weight and a data-driven process to develop a model for birth
weight.

According to the literature, maternal race, maternal age, mother’s
weight, infant sex, parity, gestational weeks, and smoking all appear to
impact birth weight. We would also expect baby’s head circumference,
baby length to be associated with birth weight.

``` r
full.model <- lm(bwt  ~., data = birthweight)

step.model <- stepAIC(full.model, direction = "backward", 
                      trace = FALSE)
summary(step.model)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ babysex + bhead + blength + delwt + fincome + 
    ##     gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1097.18  -185.52    -3.39   174.14  2353.44 
    ## 
    ## Coefficients:
    ##                     Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)       -6098.8219   137.5463 -44.340  < 2e-16 ***
    ## babysexfemale        28.5580     8.4549   3.378 0.000737 ***
    ## bhead               130.7770     3.4466  37.944  < 2e-16 ***
    ## blength              74.9471     2.0190  37.120  < 2e-16 ***
    ## delwt                 4.1067     0.3921  10.475  < 2e-16 ***
    ## fincome               0.3180     0.1747   1.820 0.068844 .  
    ## gaweeks              11.5925     1.4621   7.929 2.79e-15 ***
    ## mheight               6.5940     1.7849   3.694 0.000223 ***
    ## mraceblack         -138.7925     9.9071 -14.009  < 2e-16 ***
    ## mraceasian          -74.8868    42.3146  -1.770 0.076837 .  
    ## mracepuerto rican  -100.6781    19.3247  -5.210 1.98e-07 ***
    ## parity               96.3047    40.3362   2.388 0.017004 *  
    ## ppwt                 -2.6756     0.4274  -6.261 4.20e-10 ***
    ## smoken               -4.8434     0.5856  -8.271  < 2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 272.3 on 4328 degrees of freedom
    ## Multiple R-squared:  0.7181, Adjusted R-squared:  0.7173 
    ## F-statistic: 848.1 on 13 and 4328 DF,  p-value: < 2.2e-16

``` r
fit = lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight)
```

The model generated by stepwise selection includes many of the factors
that have been identified in the literature (race, infant sex, parity,
gestational weeks, maternal weight, and smoking). Additionally, head
circumference, length, income, and height are included in the model.

Let’s use the broom package to get a quick summary of the model and to
clean up the coefficient table.

``` r
fit %>% 
  broom::glance()
```

    ## # A tibble: 1 x 12
    ##   r.squared adj.r.squared sigma statistic p.value    df  logLik    AIC    BIC
    ##       <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>   <dbl>  <dbl>  <dbl>
    ## 1     0.718         0.717  272.      848.       0    13 -30500. 61029. 61125.
    ## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>

``` r
fit %>% broom::tidy() %>% 
  dplyr::select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

| term              |  estimate | p.value |
|:------------------|----------:|--------:|
| (Intercept)       | -6098.822 |   0.000 |
| babysexfemale     |    28.558 |   0.001 |
| bhead             |   130.777 |   0.000 |
| blength           |    74.947 |   0.000 |
| delwt             |     4.107 |   0.000 |
| fincome           |     0.318 |   0.069 |
| gaweeks           |    11.592 |   0.000 |
| mheight           |     6.594 |   0.000 |
| mraceblack        |  -138.792 |   0.000 |
| mraceasian        |   -74.887 |   0.077 |
| mracepuerto rican |  -100.678 |   0.000 |
| parity            |    96.305 |   0.017 |
| ppwt              |    -2.676 |   0.000 |
| smoken            |    -4.843 |   0.000 |

we’ll make a plot of residuals against fitted values using
add_predictions and add_residuals.

``` r
birthweight %>%
  add_residuals(fit) %>% 
  add_predictions(fit) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point()
```

![](p8105_hw6_dtw2127_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->
Let’s compare our model to 1) a model using length at birth and
gestational age as predictors 2) a model using head circumference,
length, sex and all interactions between these.

``` r
fit1 = lm(bwt ~ blength + gaweeks, data = birthweight)

fit2 = lm(bwt ~ bhead + blength + babysex + bhead:blength + bhead:babysex + blength:babysex + bhead:blength:babysex, data = birthweight) #check that the interaction terms were added correctly
```

We’ll use cross validation to compare our model to these two other
models.

The first thing we need to do is generate training and testing datasets.
We’ll generate an ID column to help with creation of these datasets.
We’ll use 80% of the data for our training dataset and 20% for our
testing dataset.

``` r
birthweight = birthweight %>%
  mutate(ID = row_number())

train_df = sample_n(birthweight, 3474)
test_df = anti_join(birthweight, train_df, by = "ID")
```

Let’s compare the distributions of the training and testing datasets
using bwt and blength.

``` r
ggplot(train_df, aes(x = blength, y = bwt)) + 
  geom_point() + 
  geom_point(data = test_df, colour = "red")
```

![](p8105_hw6_dtw2127_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->

The distributions are similar.

We’ll fit three models to the training data.

``` r
my_model = lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = train_df)

model1 = lm(bwt ~ blength + gaweeks, data = train_df)

model2 = lm(bwt ~ bhead + blength + babysex + bhead:blength + bhead:babysex + blength:babysex + bhead:blength:babysex, data = train_df)
```

Next let’s compute root mean squared errors (RMSEs).

``` r
rmse(my_model, test_df)
```

    ## [1] 299.5367

``` r
rmse(model1, test_df)
```

    ## [1] 335.0895

``` r
rmse(model2, test_df)
```

    ## [1] 314.2211

Based off the RMSEs, it suggests that my_model works the best.

We’ll iterate this process so that we can be more certain which model is
best. Let’s create many training and testing datasets. We’ll then fit
models and obtain RMSEs.

``` r
cv_df = 
  crossv_mc(birthweight, 100) #create 100 training sets. default is 80/20 training/test split. 

cv_df = 
  cv_df %>% 
  mutate(
    my_model  = map(.x = train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x))
    ) %>% 
  mutate(
    rmse_my_model = map2_dbl(my_model, test, ~rmse(model = .x, data = .y))
    )
```

    ## Warning in predict.lm(model, data): prediction from a rank-deficient fit may be
    ## misleading

``` r
cv_df = 
  cv_df %>% 
  mutate(
    model1 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x))
    ) %>% 
  mutate(
    rmse_model1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y))
    )

cv_df = 
  cv_df %>% 
  mutate(
    model2 = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead:blength + bhead:babysex + blength:babysex + bhead:blength:babysex, data = .x))
    ) %>% 
  mutate(
    rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y))
    )
```

Let’s plot the prediction error distribution for each of the three
models.

``` r
cv_df %>% 
  dplyr::select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

![](p8105_hw6_dtw2127_files/figure-gfm/unnamed-chunk-11-1.png)<!-- -->

Based on these plots, it appears that my_model is the best, followed by
model2.

## Problem 2

First we download the 2017 Central Park weather data.

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  dplyr::select(name, id, everything())
```

    ## Registered S3 method overwritten by 'hoardr':
    ##   method           from
    ##   print.cache_info httr

    ## using cached file: C:\Users\Dee\AppData\Local/Cache/R/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2021-10-05 10:32:13 (7.617)

    ## file min/max dates: 1869-01-01 / 2021-10-31

We’ll use 5000 bootstrap samples to generate estimates for r2_hat and
log(B0_hat and B1_hat).

``` r
model = lm(tmax~tmin, data = weather_df) %>% 
  broom::glance()
```

``` r
boot_straps_r_squared = 
  weather_df %>% 
  modelr::bootstrap(n = 5) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  dplyr::select(-strap, -models) %>% 
  unnest(results) %>% 
  summarize(ci_lower = quantile(r.squared, 0.025),
            ci_upper = quantile(r.squared, 0.975)) 

print(boot_straps_r_squared)
```

    ## # A tibble: 1 x 2
    ##   ci_lower ci_upper
    ##      <dbl>    <dbl>
    ## 1    0.890    0.918

``` r
boot_straps_logb0b1 = 
  weather_df %>% 
  modelr::bootstrap(n = 5) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  dplyr::select(-strap, -models) %>% 
  unnest(results) %>% 
  mutate(log_estimate = log(estimate)) %>% 
  group_by(.id) %>% 
  summarize(logb0b1 = prod(log_estimate)) %>% 
  summarize(ci_lower = quantile(logb0b1, 0.025),
            ci_upper = quantile(logb0b1, 0.975))

print(boot_straps_logb0b1)
```

    ## # A tibble: 1 x 2
    ##   ci_lower ci_upper
    ##      <dbl>    <dbl>
    ## 1   0.0506    0.102
